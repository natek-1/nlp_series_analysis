{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from nltk import sent_tokenize\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/bart-large-mnli\"\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(device=\"cpu\", model_name=model_name):\n",
    "    theme_classifier = pipeline(\n",
    "        task=\"zero-shot-classification\",\n",
    "        model=model_name,\n",
    "        device=device\n",
    "    )\n",
    "    return theme_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_classifier = load_model(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_list = [\"friendship\",\"hope\",\"sacrifice\",\"battle\",\"self development\",\"betrayal\",\"love\",\"dialogue\", \"pain\", \"hatred\", \"dream\", \"hard work\", \"war\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I gave him a right hook then a left jab',\n",
       " 'labels': ['battle',\n",
       "  'hard word',\n",
       "  'self development',\n",
       "  'pain',\n",
       "  'war',\n",
       "  'hope',\n",
       "  'hatred',\n",
       "  'dream',\n",
       "  'sacrifice',\n",
       "  'dialogue',\n",
       "  'betrayal',\n",
       "  'love',\n",
       "  'friendship'],\n",
       " 'scores': [0.9121251702308655,\n",
       "  0.5533947348594666,\n",
       "  0.4749987721443176,\n",
       "  0.4389338493347168,\n",
       "  0.35820794105529785,\n",
       "  0.08781738579273224,\n",
       "  0.0643683597445488,\n",
       "  0.04519854485988617,\n",
       "  0.04500005766749382,\n",
       "  0.020132755860686302,\n",
       "  0.012040241621434689,\n",
       "  0.0042922901920974255,\n",
       "  0.0028172011952847242]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theme_classifier(\n",
    "    \"I gave him a right hook then a left jab\",\n",
    "    theme_list,\n",
    "    multi_label=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/subtitles/Naruto Season 4 - 94.ass',\n",
       " '../data/subtitles/Naruto Season 4 - 80.ass',\n",
       " '../data/subtitles/Naruto Season 2 - 32.ass',\n",
       " '../data/subtitles/Naruto Season 8 - 185.ass',\n",
       " '../data/subtitles/Naruto Season 8 - 191.ass']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob(\"../data/subtitles/*.ass\")\n",
    "files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(files[0], \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "    lines = lines[27:] # read only the lines after the metadata\n",
    "    lines = [line.split(\",\")[9:] for line in lines] # remove all data with that is not part of the text column\n",
    "    # some sentences may have , and we don't want a 2d list \n",
    "    lines = [\"\".join(line) for line in lines] # we will combine this in the main file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We are Fighting Dreamers aiming high\\n',\n",
       " \"Fighting Dreamers\\\\Ndon't care what people think about them\\n\",\n",
       " 'Fighting Dreamers\\\\Nfollow what they believe\\n',\n",
       " 'Oli Oli Oli Oh! Just go my way\\n',\n",
       " 'Right here right now (Bang)\\\\NHit it straight like a line drive!\\n',\n",
       " 'Right here right now (Burn)\\n',\n",
       " 'Down a difficult road\\\\Nfilled with endless struggles\\n',\n",
       " \"Where do you think you are going\\\\Nfollowing someone else's map?\\n\",\n",
       " 'An insightful crow comes along\\\\Nto tear up the map\\n',\n",
       " 'Now open your eyes and\\\\Ntake a look at the truth (Yeah!)\\n']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note:* looks good however we have \\\\N character showing up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [line.replace('\\\\N', '') for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are Fighting Dreamers aiming high\n",
      " Fighting Dreamersdon't care what people think about them\n",
      " Fighting Dreamersfollow what they believe\n",
      " Oli Oli Oli Oh! Just go my way\n",
      " Right here right now (Bang)Hit it straight like a line drive!\n",
      " Right here right now (Burn)\n",
      " Down a difficult roadfilled with endless struggles\n",
      " Where do you think you are goingfollowing someone else's map?\n",
      " An insightful crow comes alongto tear up the map\n",
      " Now open your eyes andtake a look at the truth (Yeah!)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(lines[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Good*: now let us work with anotating the episode in question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/subtitles/Naruto Season 2 - 32.ass'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(files[2].split('-')[-1].split('.')[0].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_subtitles_dataset(dataset_path=\"../data/subtitles/\"):\n",
    "    subtitles_data = glob(dataset_path+\"/*.ass\")\n",
    "    \n",
    "    scripts = []\n",
    "    episode_nums = []\n",
    "    \n",
    "    for path in subtitles_data:\n",
    "        \n",
    "        # read file\n",
    "        with open(path, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "            \n",
    "        lines = lines[27:]\n",
    "        lines = [line.split(\",\")[9:] for line in lines]\n",
    "        lines = [\"\".join(line) for line in lines]\n",
    "        lines = [line.replace('\\\\N', '') for line in lines]\n",
    "        script = \" \".join(lines)\n",
    "        scripts.append(script)\n",
    "        \n",
    "        # getting the episode in question\n",
    "        episode_num = int(path.split('-')[-1].split('.')[0].strip())\n",
    "        episode_nums.append(episode_num)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict({\"episode\": episode_nums, \"script\": scripts})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_subtitles_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode</th>\n",
       "      <th>script</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94</td>\n",
       "      <td>We are Fighting Dreamers aiming high\\n Fightin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>We are Fighting Dreamers aiming high\\n Fightin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>Press down hard on the gas\\n That’s right ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>185</td>\n",
       "      <td>Rock away your existence\\n Shouting that you a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>191</td>\n",
       "      <td>Rock away your existence\\n Shouting that you a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   episode                                             script\n",
       "0       94  We are Fighting Dreamers aiming high\\n Fightin...\n",
       "1       80  We are Fighting Dreamers aiming high\\n Fightin...\n",
       "2       32  Press down hard on the gas\\n That’s right ther...\n",
       "3      185  Rock away your existence\\n Shouting that you a...\n",
       "4      191  Rock away your existence\\n Shouting that you a..."
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "script = df.iloc[0][\"script\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"We are Fighting Dreamers aiming high\\n Fighting Dreamersdon't care what people think about them\\n Fighting Dreamersfollow what they believe\\n Oli Oli Oli Oh!\",\n",
       " 'Just go my way\\n Right here right now (Bang)Hit it straight like a line drive!',\n",
       " \"Right here right now (Burn)\\n Down a difficult roadfilled with endless struggles\\n Where do you think you are goingfollowing someone else's map?\",\n",
       " 'An insightful crow comes alongto tear up the map\\n Now open your eyes andtake a look at the truth (Yeah!)',\n",
       " \"There's nothing to loseso let's GO!!!\",\n",
       " \"We are Fighting Dreamers aiming high\\n Fighting Dreamersdon't care what people think about them\\n Fighting Dreamersfollow what they believe\\n Oli Oli Oli Oh!Just go my way\\n Right here right now (Bang)Hit it straight like a line drive!\",\n",
       " \"Right here right now (Burn)We're gonna do it and do our best!\",\n",
       " 'Right here right now (Bang)Hit it straight like a line drive!',\n",
       " \"Right here right now (Burn)We're gonna do it and do our best!\",\n",
       " 'BANG!']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_sentences = sent_tokenize(script)\n",
    "script_sentences[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n"
     ]
    }
   ],
   "source": [
    "print(len(script_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create batces of sentences\n",
    "sentence_batch = 32\n",
    "script_batches = []\n",
    "for index in range(0, len(script_sentences), sentence_batch):\n",
    "    sent = \"\"\n",
    "    if index+sentence_batch <= len(script_sentences): \n",
    "        sent = \" \".join(script_sentences[index:index+sentence_batch])\n",
    "    else:\n",
    "        sent = \" \".join(script_sentences[index:-1])\n",
    "    script_batches.append(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(device=\"cpu\", model_name=model_name):\n",
    "    theme_classifier = pipeline(\n",
    "        task=\"zero-shot-classification\",\n",
    "        model=model_name,\n",
    "        device=device\n",
    "    )\n",
    "    return theme_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/bart-large-mnli\"\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "theme_list = [\"friendship\",\"hope\",\"sacrifice\",\"battle\",\"self development\",\"betrayal\",\"love\",\"dialogue\", \"pain\", \"hatred\", \"dream\", \"hard work\", \"war\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ngkuissi/miniforge3/envs/series_analysis/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/Users/ngkuissi/miniforge3/envs/series_analysis/lib/python3.9/site-packages/torch/utils/data/dataloader.py:718: UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator object at 0x332b81880> was reported to be 2(when accessing len(dataloader)), but 3 samples have been fetched. \n",
      "  warnings.warn(warn_msg)\n",
      "/Users/ngkuissi/miniforge3/envs/series_analysis/lib/python3.9/site-packages/torch/utils/data/dataloader.py:718: UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator object at 0x332b81880> was reported to be 2(when accessing len(dataloader)), but 4 samples have been fetched. \n",
      "  warnings.warn(warn_msg)\n",
      "/Users/ngkuissi/miniforge3/envs/series_analysis/lib/python3.9/site-packages/torch/utils/data/dataloader.py:718: UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator object at 0x332b81880> was reported to be 2(when accessing len(dataloader)), but 5 samples have been fetched. \n",
      "  warnings.warn(warn_msg)\n",
      "/Users/ngkuissi/miniforge3/envs/series_analysis/lib/python3.9/site-packages/torch/utils/data/dataloader.py:718: UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator object at 0x332b81880> was reported to be 2(when accessing len(dataloader)), but 6 samples have been fetched. \n",
      "  warnings.warn(warn_msg)\n",
      "/Users/ngkuissi/miniforge3/envs/series_analysis/lib/python3.9/site-packages/torch/utils/data/dataloader.py:718: UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator object at 0x332b81880> was reported to be 2(when accessing len(dataloader)), but 7 samples have been fetched. \n",
      "  warnings.warn(warn_msg)\n",
      "/Users/ngkuissi/miniforge3/envs/series_analysis/lib/python3.9/site-packages/torch/utils/data/dataloader.py:718: UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator object at 0x332b81880> was reported to be 2(when accessing len(dataloader)), but 8 samples have been fetched. \n",
      "  warnings.warn(warn_msg)\n",
      "/Users/ngkuissi/miniforge3/envs/series_analysis/lib/python3.9/site-packages/torch/utils/data/dataloader.py:718: UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator object at 0x332b81880> was reported to be 2(when accessing len(dataloader)), but 9 samples have been fetched. \n",
      "  warnings.warn(warn_msg)\n",
      "/Users/ngkuissi/miniforge3/envs/series_analysis/lib/python3.9/site-packages/torch/utils/data/dataloader.py:718: UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator object at 0x332b81880> was reported to be 2(when accessing len(dataloader)), but 10 samples have been fetched. \n",
      "  warnings.warn(warn_msg)\n",
      "/Users/ngkuissi/miniforge3/envs/series_analysis/lib/python3.9/site-packages/torch/utils/data/dataloader.py:718: UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator object at 0x332b81880> was reported to be 2(when accessing len(dataloader)), but 11 samples have been fetched. \n",
      "  warnings.warn(warn_msg)\n",
      "/Users/ngkuissi/miniforge3/envs/series_analysis/lib/python3.9/site-packages/torch/utils/data/dataloader.py:718: UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator object at 0x332b81880> was reported to be 2(when accessing len(dataloader)), but 12 samples have been fetched. \n",
      "  warnings.warn(warn_msg)\n",
      "/Users/ngkuissi/miniforge3/envs/series_analysis/lib/python3.9/site-packages/torch/utils/data/dataloader.py:718: UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator object at 0x332b81880> was reported to be 2(when accessing len(dataloader)), but 13 samples have been fetched. \n",
      "  warnings.warn(warn_msg)\n",
      "/Users/ngkuissi/miniforge3/envs/series_analysis/lib/python3.9/site-packages/torch/utils/data/dataloader.py:718: UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator object at 0x332b81880> was reported to be 2(when accessing len(dataloader)), but 14 samples have been fetched. \n",
      "  warnings.warn(warn_msg)\n",
      "/Users/ngkuissi/miniforge3/envs/series_analysis/lib/python3.9/site-packages/torch/utils/data/dataloader.py:718: UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator object at 0x332b81880> was reported to be 2(when accessing len(dataloader)), but 15 samples have been fetched. \n",
      "  warnings.warn(warn_msg)\n",
      "/Users/ngkuissi/miniforge3/envs/series_analysis/lib/python3.9/site-packages/torch/utils/data/dataloader.py:718: UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator object at 0x332b81880> was reported to be 2(when accessing len(dataloader)), but 16 samples have been fetched. \n",
      "  warnings.warn(warn_msg)\n",
      "/Users/ngkuissi/miniforge3/envs/series_analysis/lib/python3.9/site-packages/torch/utils/data/dataloader.py:718: UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator object at 0x332b81880> was reported to be 2(when accessing len(dataloader)), but 17 samples have been fetched. \n",
      "  warnings.warn(warn_msg)\n",
      "/Users/ngkuissi/miniforge3/envs/series_analysis/lib/python3.9/site-packages/torch/utils/data/dataloader.py:718: UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator object at 0x332b81880> was reported to be 2(when accessing len(dataloader)), but 18 samples have been fetched. \n",
      "  warnings.warn(warn_msg)\n",
      "/Users/ngkuissi/miniforge3/envs/series_analysis/lib/python3.9/site-packages/torch/utils/data/dataloader.py:718: UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator object at 0x332b81880> was reported to be 2(when accessing len(dataloader)), but 19 samples have been fetched. \n",
      "  warnings.warn(warn_msg)\n",
      "/Users/ngkuissi/miniforge3/envs/series_analysis/lib/python3.9/site-packages/torch/utils/data/dataloader.py:718: UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator object at 0x332b81880> was reported to be 2(when accessing len(dataloader)), but 20 samples have been fetched. \n",
      "  warnings.warn(warn_msg)\n",
      "/Users/ngkuissi/miniforge3/envs/series_analysis/lib/python3.9/site-packages/torch/utils/data/dataloader.py:718: UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator object at 0x332b81880> was reported to be 2(when accessing len(dataloader)), but 21 samples have been fetched. \n",
      "  warnings.warn(warn_msg)\n",
      "/Users/ngkuissi/miniforge3/envs/series_analysis/lib/python3.9/site-packages/torch/utils/data/dataloader.py:718: UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator object at 0x332b81880> was reported to be 2(when accessing len(dataloader)), but 22 samples have been fetched. \n",
      "  warnings.warn(warn_msg)\n",
      "/Users/ngkuissi/miniforge3/envs/series_analysis/lib/python3.9/site-packages/torch/utils/data/dataloader.py:718: UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator object at 0x332b81880> was reported to be 2(when accessing len(dataloader)), but 23 samples have been fetched. \n",
      "  warnings.warn(warn_msg)\n",
      "/Users/ngkuissi/miniforge3/envs/series_analysis/lib/python3.9/site-packages/torch/utils/data/dataloader.py:718: UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator object at 0x332b81880> was reported to be 2(when accessing len(dataloader)), but 24 samples have been fetched. \n",
      "  warnings.warn(warn_msg)\n",
      "/Users/ngkuissi/miniforge3/envs/series_analysis/lib/python3.9/site-packages/torch/utils/data/dataloader.py:718: UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator object at 0x332b81880> was reported to be 2(when accessing len(dataloader)), but 25 samples have been fetched. \n",
      "  warnings.warn(warn_msg)\n",
      "/Users/ngkuissi/miniforge3/envs/series_analysis/lib/python3.9/site-packages/torch/utils/data/dataloader.py:718: UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator object at 0x332b81880> was reported to be 2(when accessing len(dataloader)), but 26 samples have been fetched. \n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "theme_classifier = load_model(device=device)\n",
    "theme_output = theme_classifier(\n",
    "    script_batches[:2],\n",
    "    theme_list,\n",
    "    multi_label=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "series_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
